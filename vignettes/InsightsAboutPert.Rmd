---
title: "Insights about Pert"
author: "Dr. Jan Seifert"
date: "30 3 2021"
output: html_document
bibliography: ["pert.bib"]
biblio-style: "apalike"
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("../R/threepoint_core.R")
```

A Pert distribution with a range from $a$ to $c$ and a mode of $b$. This note book tries to solve some puzzles regarding the Pert distribution. 



# Mean and Standard Deviation

## Mean

Every source says that the mean of the Pert distribution was:

$$ \operatorname {E} [X]= \frac{a+4b+c}{6} = \frac{a+k \cdot b+c}{k+2} = \mu $$

Strangely, this is also the same equation of the [double triangular distribution](http://www.mhnederlof.nl/doubletriangular.html) [as noted by @Henry27280]. However, I couldn't find any reason or source that justifies the connection for that and it seems like a coincidence.

Looking closer at the mathematics it becomes clear that the Pert distribution cannot guarantee the specified mean. It is a special case of the beta distribution. The general formula for the mean of the $beta(\alpha, \beta, a, c)$ distributions is [@enwiki1011418887; @Treat1983]:

$$
\mu = \frac\alpha{\alpha+\beta} \cdot (c-a) + a = \frac{\alpha c + \beta a}{\alpha+\beta}
$$

So, it is clear that it is not at all determined by the max/min parameters. It is also influenced by two parameters α and β. For a long time these have defined as

$$ \alpha = {(\mu - a) (2 \cdot b-a-c)\over (b-\mu) (c - a)} $$

and

$$ \beta = \alpha \cdot {(c - \mu) \over (\mu - a)} $$



## Standard Deviation
 
The standard deviation of the Pert distribution is known as one sixth of it's total range.

$$ \sigma = {c - a \over 6} = \frac{1}{6}(c - a)$$

However, that is an approximation. The exact formula for the variance is [@enwiki1001556353]

$$
\sigma^2 = \frac{(\mu-a)(c-\mu)}{7}
$$

or in terms of the beta distribution:

 $$ \text{var}(X)(c-a)^2 = 
    \frac{\alpha\beta (c-a)^2} {(\alpha+\beta)^2(\alpha+\beta+1)} $$


Given the above formula of the Pert mean and the fact that the standard deviation is the square root of the variance this is the exact formula.

$$
\sigma = 
\sqrt{\frac{(\mu-a)(c-\mu)}{7}} = \\ 
\frac{1}{6} \cdot \sqrt{ \frac{5 a^2 + 16ab - 26ac - 16b^2 + 16bc + 5 c^2}{7} }
$$

Let us simplify this by setting the min $a=0$ and the max value $c=1$ for demonstration purposes. That leaves:

$$
\sigma = 
\frac{1}{6} \cdot \sqrt{ \frac{- 16b^2 + 16b + 5}{7} } = \frac{1}{6} \cdot \sqrt{ \frac{5 - 16 (b - 1) b}{7} }
$$

```{r}
library(ggplot2)
b <- seq(0, 1, 0.05)
sigma <- sqrt( (5-16*(b-1)*b) / 7 ) / 6
data <- data.frame(b, sigma)
ggplot(data, aes(x = b, y = sigma)) + geom_line()
```

As we can see the standard deviation depends on the most likely estimate $b$. It ranges around 1/6 = `r format(1/6, digits=2, nsmall = 3)` from `r format(min(sigma), digits=2, nsmall = 3)` to `r format(max(sigma), digits=2, nsmall = 3)`. Such variations are why @Farnum1987 warned about using the approximation in extreme cases when the most-likely estimate is close to the minimum or maximum, i. e. close than 13% of the total range.


## Synthesis?

How can these discrepancy be addressed? I found three approaches in the literature.

 1. Find ways to parametrize the beta distribution exactly to guarantee the defined mean and standard deviation [@Davis2008].
 1. Find new equations that give the correct (or a more correct) mean and standard deviation [e.g. @Lau1998; @GolenkoGinzburg1988; summarized and challenged by @Perez2017].
 1. Yet others investigate the relation between mean/standard deviation and the shape parameter of the Pert distribution [see @Pleguezuelo2003].


Would it not be interesting if we could really make a fixed standard deviation possible? If we solve the equations for a simple example it becomes clear that there is a discrepancy. The plot shows the variances (y-axis) depending on mode (x-axis), and the parametrization method (colour). The variances of Davis and Vose have been moved a little bit to the right because it would not be possible to dinstinguish those from other equations.

```{r echo=FALSE}
library(ggplot2)
min <- -1
max <- +1
shape <- 4

mode <- seq(min, max, 0.05)

# Compute approximate value
#mu <- (min + shape * mode + max)/(shape + 2)
#stdev <- (max-min) / 6

Data <- data.frame(Mode = numeric(), 
                   Mean = numeric(), 
                   Var = numeric(), 
                   Method = character())
Jitter  <- c(classic = -0.02, golgin = -0.04, vose = 0.03, davis = 0.04, Theoretical = 0.00)

# Compute using different paramtrization methods
for (m in c("classic", "golgin", "vose", "davis")) {
  Params <- Pert2BetaParams(min, mode, max, shape, m)
  tMean  <- Params$alpha / (Params$alpha+Params$beta) * (max-min) + min
  tVar   <- (max-min)^2 * Params$alpha * Params$beta / 
            (Params$alpha+Params$beta)^2 / (Params$alpha+Params$beta+1)
  Data <- rbind(Data, data.frame(Mode = mode + Jitter[m], 
                                 Mean = tMean, 
                                 Var  = tVar, 
                                 Method = rep(m, length(mode))))
}

# Add theoretical values
Data <- rbind(Data, data.frame(Mode = mode + Jitter[m], 
                               Mean = (min + shape * mode + max)/(shape + 2), 
                               Var  = (max-min)^2 / 36, 
                               Method = rep("Theoretical", length(mode))))

# Plot
ggplot(Data, aes(x = Mode, y = Var, colour = Method)) +
  geom_line(size = 3/4) + theme_linedraw() + 
  scale_color_manual(values = c("sienna1", "tan4", "hotpink1", "black", "darkmagenta")) + 
  labs(x = "Var", y = "Mode")
```

As we can see the parametrization @Davis2008 works. He proposes a new way to estimate the α and β parameters of the beta distribution to make sure that mean and standard deviation are fixed to the defined values:

$$   \alpha = \frac{2 \cdot (c + 4b - 5a)} {3(c-a)} \cdot 
       \left[ 1 + 4 \cdot \frac{(b-a)\cdot(c-b)}{(c-a)^2} \right] $$

$$   \beta = \alpha \cdot \frac{5c-4b-a}{c+4b-5a} $$

What is most interesting and baffling is the observation that the classic parametrization of the beta distribution shows the exact same pattern, i.e. no deviation from a fixed variance of 1/36.

```{r}
Jitter  <- c(classic = -0.02, golgin = 0.02, vose = 0.04, davis = 0.06, Theoretical = 0.00)
ggplot(Data, aes(x = Mode, y = Mean, colour = Method)) +
  geom_line(size = 3/4) + theme_linedraw() + 
  scale_color_manual(values = c("sienna1", "tan4", "hotpink1", "black", "darkmagenta")) + 
  labs(x = "Mean", y = "Mode")
```


A similar experiment with distribution means shows no deviation from the mean. Regardless of the parametrization method 



All in all, @Davis2008 handles the inconsistency. It is probably better to avoid the `pert` distribution family of the [mc2d](https://rdrr.io/cran/mc2d/) [@Pouillot2010a] package. Instead, compute α and β using the equations from @Davis2008 and use the generalized [beta distribution (betagen)](https://rdrr.io/cran/mc2d/man/betagen.html) instead.




## Median

A rough estimate of the median is [@enwiki1011418887]

$$ Median = \frac{(a + 6*b + c)}{8} $$

The actual definition of the median is 

$$ I_{\frac {1}{2}}^{[-1]}(\alpha, \beta ) (c-a) + a $$
for which the regularized incomplete beta function 

$$ {\displaystyle I_{x}(\alpha,\beta )={\tfrac {1}{2}}}I_x(\alpha,\beta) = \tfrac{1}{2}$$. 

However, there is no general closed-form expression for the median of the beta distribution for arbitrary values of α and β. Yet, it can easily be done in R with `qpert(0.5, min=a, mode=b, max=c)` (using the mc2d package) or with `qbeta(0.5, alpha, beta) * (c - a) + a`.





# Parametrization of the Beta distributions

## Classic

According to @Pouillot2010a this equation is from @Malcolm1959 but I was unable to find it there. Lacking a better source this is from @Pouillot2010a. That is the first reason, why I somewhat doubted the following equation. The second reason is because - [according to the author](https://www.vosesoftware.com/riskwiki/ModifiedPERTdistribution.php) - the `shape` parameter was introduced by @Vose2000 and Vose proposes his own set of formulas. The original publications - it seems - did not intend to change the shape parameter and assumed a fixed shape = 4. Furthermore, the classic formulas as presented by @Pouillot2010a (as shown below) are equivalent to those by @Davis2008.


$$
\begin{aligned}
    \mu &= \frac{a + shape * b + c} {shape + 2} \\
    \sigma &= \frac{c - a}{shape + 2} \\
    \alpha &= \frac{\mu - a}{c - a} \cdot \left( \frac{(\mu - a) * (c - \mu)}{\sigma^2} - 1 \right)  \\ 
           &= \frac{\mu - a}{c - a} \cdot \left( \frac{(\mu - a) * (c - \mu) (shape + 2)^2}{(c - a)^2} - 1 \right)     \\
           &= \frac{shape (a - c + a shape - b shape) ((a - c)^2 + (a - b) (b - c) shape)} {(a - c)^3 (2 + shape)}     \\
    \beta &= \alpha \cdot \frac{c - \mu}{\mu - a}
\end{aligned}
$$


## Golenko-Ginzburg (GolGin)

Golenko-Ginzburg [-@GolenkoGinzburg1988; cited by @Pleguezuelo2003] proposed this parametrization:

$$
α = 1 + k * \frac{b − a}{c − a} \\
β = 1 + k * \frac{c − b}{c − a}
$$

## Vose

@Vose2008 uses:

$$
\begin{aligned}
  \alpha &= \frac{(\mu - a)(2b-a-c)}{(b-\mu)(c-a)} \\
         &= \frac{(c + 4b - 5a)}{(c - a)}\\
  \beta  &= \frac{\alpha (c - \mu)}{\mu - a} \\
  \text{with } \mu &= \frac{a + 4b + c}{6}
\end{aligned}
$$


## Davis

@Davis2008 finally uses 

$$
\begin{aligned}
  \alpha &= \frac{2(c+4b-5a)}{3(c-a)} \cdot 
            \left[ 1+4(\frac{(b-a)(c-b)}{(c-a)^2}) \right] \\
  \beta  &= \frac{2(5c-4b-a)}{3(c-a)} \cdot 
            \left[ 1+4(\frac{(b-a)(c-b)}{(c-a)^2}) \right]
\end{aligned}
$$


Comparing these three approaches, the plot below shows how the beta parameters (y axis) change depending on the position of the mode. The distribution ranges from `a = min = -1` to `b = max = 1` The position of the mode is shown on the x-axis ranges from `min` to `max`. The curves for Vose and Davis are slightly offset because some curves would be too similar to be distinguished.

There is a clear difference between the parameters proposed by Vose and Davis. The Classic parameter, however, cannot be found. It hides behind Davis' parameter curves. That fuels my doubt regarding the classic beta parameter equations proposed by @Pouillot2010a.

The Golenko-Ginzburg parameters are hidden, too, and hide behind Vose's parameters.


```{r echo=FALSE}
library(ggplot2)
min  <- -1
max  <- +1
x    <- seq(min, max, 0.05)
Span <- length(x)

Methods <- c("classic", "golgin", "vose" ,"davis") #
Jitter  <- c(classic = 0, golgin = 0, vose = 0.03, davis = 0.03)
ML <- length(Methods)
Params  <- c("alpha", "beta")
PL <- length(Params)

Data <- data.frame(
  x      = rep(x, ML*PL),
  method = rep(Methods, each = Span*PL),
  param  = rep(rep(Params, each = Span), ML),
  value  = rep(0, ML * PL * Span)
)

for (m in Methods) {
  y <- Pert2BetaParams(min, x, max, 4, m)
  
  Index <- (match(m, Methods) - 1) * Span*2L + 1
  Data[["value"]][Index:(Index+Span-1)] <- y$alpha + Jitter[m]

  Index <- Index + Span
  Data[["value"]][Index:(Index+Span-1)] <- y$beta + Jitter[m]
}
ggplot(Data, aes(x = x, y = value, colour = method, linetype = param)) + 
  geom_line(size = 2/3) + theme_linedraw() + 
  scale_color_manual(values = c("sienna1", "tan4", "hotpink1", "darkmagenta")) + 
  labs(x = "Mode", y = "beta parameter")
```

Or maybe all this tells another story. Maybe @Malcolm1959 got it right in the first place and were misinterpreted later causing a lot of confusion. Let us look at a few words from @Clark1962:

> However, the beta distribution still has a free parameter after its mode and extremes are designated.

The authors are obviously fully aware of the fact that the beta distribution is still ambiguous unless further assumptions are made. So, @Clark1962 continues:

> Suppose we select one-sixth of the range as the standard deviation (the normal distribution truncated at ±2.66) has its standard deviation 1/6 fo the range, and we feel that this truncated normal distribution is an appropriate simple model for specifying the ratio of the standard deviation to the range). 

Which could be the assumption capable of defining the Pert beta distribution. And - indeed - @Clark1962 finishes:

> Then a beta distribution is determined, and one can convert the mode and extremes into the expected value and variance.

That sounds like @Malcolm1959 and @Clark1962 had already done what @Davis2008 (re-?) invented 46 years later because the original intention of the authors was misunderstood. A glance at Appendix B of @US1958 seems to confirm that notion. But, of course, without further knowledge this is just a hypothesis.




# The Four-Parameter Beta Distributions

Pert is based on the Beta distribution. While the standard definition of the beta distribution has a range of $[0, 1]$ a re-parametrized version with four parameters allows setting a range $[a, c]$, too. 

Mean [@enwiki1011418887; @Treat1983]

$$
\mu_1 = \frac{\alpha}{\alpha+\beta} (c - a) + a
$$

Variance [@Treat1983]

$$
\mu_2 = \frac{(c-a)^2 \alpha\beta}{(\alpha+\beta)^2 (\alpha+\beta+1)}
$$

"Since the skewness and excess kurtosis are non-dimensional quantities (as moments centered on the mean and normalized by the standard deviation), they are independent of the parameters a and c" [@enwiki1011418887]

Skewness [@Treat1983]
$$
\mu_3 = \frac{2 (\beta-\alpha) \sqrt{\alpha+\beta+1}}{(\alpha+\beta+2)\sqrt{\alpha\beta}}
$$

Kurtosis [equations taken from @Treat1983; and @enwiki1011418887, but it is unclear if they are equivalent].

$$
\mu_4 = \frac{3 (\alpha+\beta+1) [2(\alpha+\beta)^2 + \alpha\beta (\alpha+\beta-6)]} {\alpha\beta (\alpha+\beta+2) (\alpha+\beta+3)} 
= \frac{6[(\alpha - \beta)^2 (\alpha +\beta + 1) - \alpha \beta (\alpha + \beta + 2)]}
{\alpha \beta (\alpha + \beta + 2) (\alpha + \beta + 3)} 
$$



# References